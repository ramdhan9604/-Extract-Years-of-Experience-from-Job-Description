{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11706383,"sourceType":"datasetVersion","datasetId":7347893}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers tqdm spacy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T20:40:44.534608Z","iopub.execute_input":"2025-05-06T20:40:44.535215Z","iopub.status.idle":"2025-05-06T20:40:48.518559Z","shell.execute_reply.started":"2025-05-06T20:40:44.535191Z","shell.execute_reply":"2025-05-06T20:40:48.517876Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.1)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!python -m spacy download en_core_web_sm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T20:41:15.010119Z","iopub.execute_input":"2025-05-06T20:41:15.010403Z","iopub.status.idle":"2025-05-06T20:41:26.834738Z","shell.execute_reply.started":"2025-05-06T20:41:15.010380Z","shell.execute_reply":"2025-05-06T20:41:26.833940Z"}},"outputs":[{"name":"stdout","text":"Collecting en-core-web-sm==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.11.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.33.1)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.13.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport numpy as np\nimport concurrent.futures\nimport time\nfrom transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\nimport torch\nimport spacy\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Load SpaCy model\ntry:\n    nlp = spacy.load(\"en_core_web_sm\")\nexcept:\n    # If model isn't installed, download it\n    spacy.cli.download(\"en_core_web_sm\")\n    nlp = spacy.load(\"en_core_web_sm\")\n\n# Function to read the Excel file\ndef read_jd_data(file_path):\n    \"\"\"Read job descriptions from Excel file.\"\"\"\n    try:\n        df = pd.read_excel(file_path)\n        print(f\"Successfully loaded {len(df)} job descriptions\")\n        return df\n    except Exception as e:\n        print(f\"Error loading file: {e}\")\n        return pd.DataFrame()\n\n# Model 1: Rule-based Regex Pattern Matching\ndef extract_experience_regex(text):\n    \"\"\"\n    Extract experience requirements using regex patterns.\n    Handles various formats like \"X+ years\", \"X to Y years\", \"minimum X years\", etc.\n    \"\"\"\n    if pd.isna(text) or not isinstance(text, str):\n        return None\n    \n    # Clean text - remove newlines, extra spaces\n    text = re.sub(r'\\s+', ' ', text)\n    \n    # Pattern for explicit year mentions\n    patterns = [\n        r'(\\d+\\+)\\s*years?\\s+(?:of\\s+)?(?:work\\s+)?(?:experience|exp)',  # 5+ years experience\n        r'(\\d+)[-–]\\s*(\\d+)\\s+years?\\s+(?:of\\s+)?(?:work\\s+)?(?:experience|exp)',  # 5-7 years experience\n        r'minimum\\s+(?:of\\s+)?(\\d+)\\s+years?\\s+(?:of\\s+)?(?:work\\s+)?(?:experience|exp)',  # minimum 5 years experience\n        r'at\\s+least\\s+(\\d+)\\s+years?\\s+(?:of\\s+)?(?:work\\s+)?(?:experience|exp)',  # at least 5 years experience\n        r'(\\d+)\\s+(?:or\\s+)?more\\s+years?\\s+(?:of\\s+)?(?:work\\s+)?(?:experience|exp)',  # 5 or more years experience\n        r'(?:with\\s+)?(\\d+)\\s+years?\\s+(?:of\\s+)?(?:work\\s+)?(?:experience|exp)',  # with 5 years experience\n        r'experience:?\\s+(\\d+)(?:\\+)?\\s+years?',  # experience: 5+ years\n        r'(?:work\\s+)?experience\\s+(?:of\\s+)?(?:at\\s+least\\s+)?(\\d+)(?:\\+)?\\s+years?'  # work experience of 5+ years\n    ]\n    \n    # Check for job titles with experience\n    title_exp_pattern = r'(?:senior|sr\\.?|lead|principal|experienced|staff)\\s+([a-zA-Z\\s]+)'\n    \n    # Check for seniority levels\n    seniority_mapping = {\n        'entry level': 0, \n        'junior': 1,\n        'mid-level': 3,\n        'intermediate': 3,\n        'senior': 5,\n        'lead': 7,\n        'principal': 8,\n        'director': 10,\n        'executive': 12,\n        'vp': 15,\n        'chief': 15\n    }\n    \n    # First try to find explicit year mentions\n    for pattern in patterns:\n        matches = re.findall(pattern, text.lower())\n        if matches:\n            if isinstance(matches[0], tuple):  # For ranges like \"5-7 years\"\n                min_years, max_years = matches[0]\n                return (int(min_years) + int(max_years)) / 2  # Return average as estimation\n            elif matches[0].endswith('+'):  # For \"5+\" format\n                return int(matches[0][:-1])\n            else:\n                return int(matches[0])\n    \n    # If no explicit years, check for seniority in job title\n    title_match = re.search(title_exp_pattern, text.lower())\n    if title_match:\n        for level, years in seniority_mapping.items():\n            if level in text.lower():\n                return years\n    \n    # Look for seniority mentions in the text\n    for level, years in seniority_mapping.items():\n        if level in text.lower():\n            return years\n    \n    return None\n\n# Model 2: SpaCy NER with Custom Rules\ndef extract_experience_spacy(text):\n    \"\"\"Extract experience using SpaCy NER and custom rules.\"\"\"\n    if pd.isna(text) or not isinstance(text, str):\n        return None\n    \n    # Process text with SpaCy\n    doc = nlp(text)\n    \n    # Look for sentences containing experience-related terms\n    experience_sentences = []\n    for sent in doc.sents:\n        sent_text = sent.text.lower()\n        if any(term in sent_text for term in [\"experience\", \"experienced\", \"years\", \"year\"]):\n            experience_sentences.append(sent_text)\n    \n    # If no relevant sentences found, return None\n    if not experience_sentences:\n        return None\n    \n    # Apply regex patterns to these specific sentences for more targeted extraction\n    combined_text = \" \".join(experience_sentences)\n    \n    # Use the same regex patterns as in the regex function\n    return extract_experience_regex(combined_text)\n\n# Model 3: GPT-based Zero-shot Classification\ndef extract_experience_zero_shot(text, classifier):\n    \"\"\"Extract experience using zero-shot classification.\"\"\"\n    if pd.isna(text) or not isinstance(text, str):\n        return None\n    \n    # First try to find experience requirements in text\n    candidate_labels = [\"0 years\", \"1-2 years\", \"3-5 years\", \"5-7 years\", \"7-10 years\", \"10+ years\"]\n    \n    try:\n        # Use smaller chunks of text to avoid token limits\n        chunks = [text[i:i+512] for i in range(0, len(text), 512)]\n        results = []\n        \n        for chunk in chunks:\n            if any(term in chunk.lower() for term in [\"experience\", \"years\", \"senior\", \"junior\"]):\n                result = classifier(chunk, candidate_labels)\n                results.append(result)\n        \n        if not results:\n            return None\n        \n        # Find the most confident result\n        best_result = max(results, key=lambda x: max(x['scores']))\n        \n        # Map label to numeric value\n        label_to_years = {\n            \"0 years\": 0,\n            \"1-2 years\": 1.5,\n            \"3-5 years\": 4,\n            \"5-7 years\": 6,\n            \"7-10 years\": 8.5,\n            \"10+ years\": 12\n        }\n        \n        return label_to_years[best_result['labels'][0]]\n    except Exception as e:\n        print(f\"Error in zero-shot classification: {e}\")\n        return None\n\n# Model 4: Transformer-based Sequence Classification\nclass ExperienceClassifier:\n    def __init__(self):\n        # Initialize tokenizer and model for fine-tuned BERT\n        # Note: In a real implementation, you would fine-tune a model on labeled data\n        self.tokenizer = None\n        self.model = None\n        self.initialized = False\n        \n    def initialize(self):\n        \"\"\"Initialize the model - here using a sentiment model as proxy.\"\"\"\n        # In a real implementation, you would load a custom fine-tuned model\n        # For this demonstration, we'll use a sentiment model as a stand-in\n        try:\n            self.tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n            self.model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n            self.initialized = True\n        except Exception as e:\n            print(f\"Error initializing transformer model: {e}\")\n    \n    def extract_experience(self, text):\n        \"\"\"Extract experience using sequence classification.\"\"\"\n        if pd.isna(text) or not isinstance(text, str):\n            return None\n        \n        if not self.initialized:\n            self.initialize()\n            \n        if not self.initialized:\n            return None\n            \n        try:\n            # Extract sentences containing experience-related terms\n            sentences = re.split(r'[.!?]', text)\n            experience_sentences = [s for s in sentences if any(term in s.lower() for term in [\"experience\", \"years\"])]\n            \n            if not experience_sentences:\n                return None\n            \n            # Process sentences through model\n            combined_text = \" \".join(experience_sentences)\n            \n            # In a real implementation, this would use a custom model\n            # For this demonstration, we'll fallback to regex after finding relevant sentences\n            return extract_experience_regex(combined_text)\n            \n        except Exception as e:\n            print(f\"Error in transformer classification: {e}\")\n            return None\n\n# Model 5: Named Entity Recognition with Custom Rules\ndef extract_experience_custom_ner(text):\n    \"\"\"Extract experience using custom NER rules.\"\"\"\n    if pd.isna(text) or not isinstance(text, str):\n        return None\n    \n    # Process text\n    text = text.lower()\n    \n    # Dictionary of experience level terms and corresponding years\n    experience_levels = {\n        'entry level': 0,\n        'entry-level': 0,\n        'beginner': 0,\n        'junior': 1,\n        'mid level': 3,\n        'mid-level': 3,\n        'intermediate': 3,\n        'experienced': 5,\n        'senior': 5,\n        'expert': 7,\n        'lead': 7,\n        'principal': 8,\n        'director': 10,\n        'executive': 12\n    }\n    \n    # Check for seniority terms\n    for level, years in experience_levels.items():\n        pattern = fr'\\b{re.escape(level)}\\b'\n        if re.search(pattern, text):\n            return years\n    \n    # If no seniority terms found, use regex patterns\n    return extract_experience_regex(text)\n\n# Model 6: Hybrid Text Classification with Feature Extraction\ndef extract_experience_hybrid(text):\n    \"\"\"\n    A hybrid approach combining multiple strategies:\n    1. Look for explicit mentions of years\n    2. Identify seniority levels\n    3. Detect implicit experience requirements\n    \"\"\"\n    if pd.isna(text) or not isinstance(text, str):\n        return None\n    \n    # 1. Try regex patterns first\n    regex_result = extract_experience_regex(text)\n    if regex_result is not None:\n        return regex_result\n    \n    # 2. Try custom NER\n    ner_result = extract_experience_custom_ner(text)\n    if ner_result is not None:\n        return ner_result\n    \n    # 3. Look for education requirements as proxy for experience\n    edu_patterns = {\n        r'phd': 8,\n        r'doctorate': 8,\n        r'master\\'?s': 5,\n        r'mba': 5,\n        r'bachelor\\'?s': 3,\n        r'bs': 3,\n        r'ba': 3,\n        r'associate\\'?s': 1\n    }\n    \n    for pattern, years in edu_patterns.items():\n        if re.search(fr'\\b{pattern}\\b', text.lower()):\n            return years\n    \n    # 4. Check for skill proficiency as proxy\n    skill_levels = {\n        'advanced': 5,\n        'proficient': 3,\n        'familiar': 1\n    }\n    \n    for level, years in skill_levels.items():\n        if re.search(fr'\\b{level}\\b', text.lower()):\n            return years\n    \n    return None\n\n# Function to extract experience using all models\ndef process_jd(jd, zero_shot_classifier=None, experience_classifier=None):\n    \"\"\"Process a single JD with all models and return results.\"\"\"\n    regex_result = extract_experience_regex(jd)\n    spacy_result = extract_experience_spacy(jd)\n    zero_shot_result = extract_experience_zero_shot(jd, zero_shot_classifier) if zero_shot_classifier else None\n    transformer_result = experience_classifier.extract_experience(jd) if experience_classifier else None\n    custom_ner_result = extract_experience_custom_ner(jd)\n    hybrid_result = extract_experience_hybrid(jd)\n    \n    return {\n        'Regex': regex_result,\n        'SpaCy': spacy_result,\n        'Zero-Shot': zero_shot_result,\n        'Transformer': transformer_result,\n        'Custom NER': custom_ner_result,\n        'Hybrid': hybrid_result\n    }\n\n# Function to process all JDs in parallel\ndef process_all_jds(df, jd_column='JD_Text'):\n    \"\"\"Process all JDs in the dataframe.\"\"\"\n    print(\"Initializing models...\")\n    \n    # Initialize zero-shot classifier\n    try:\n        zero_shot_classifier = pipeline(\"zero-shot-classification\", \n                                        model=\"facebook/bart-large-mnli\", \n                                        device=0 if torch.cuda.is_available() else -1)\n    except Exception as e:\n        print(f\"Error initializing zero-shot classifier, will skip this model: {e}\")\n        zero_shot_classifier = None\n    \n    # Initialize transformer classifier\n    experience_classifier = ExperienceClassifier()\n    \n    results = []\n    \n    print(\"Processing job descriptions...\")\n    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n        # Submit tasks\n        future_to_index = {executor.submit(process_jd, \n                                          row[jd_column], \n                                          zero_shot_classifier, \n                                          experience_classifier): i \n                          for i, row in df.iterrows()}\n        \n        # Process results as they complete\n        for future in tqdm(concurrent.futures.as_completed(future_to_index), total=len(df)):\n            index = future_to_index[future]\n            try:\n                result = future.result()\n                result['Index'] = index\n                results.append(result)\n            except Exception as e:\n                print(f\"Error processing JD at index {index}: {e}\")\n    \n    # Convert results to DataFrame\n    results_df = pd.DataFrame(results)\n    results_df = results_df.sort_values('Index')\n    results_df.set_index('Index', inplace=True)\n    \n    # Join with original dataframe\n    output_df = df.join(results_df)\n    \n    # Calculate agreement metrics and add recommendation\n    output_df = analyze_model_performance(output_df)\n    \n    return output_df\n\n# Function to analyze model performance\ndef analyze_model_performance(df):\n    \"\"\"Analyze performance of each model and add recommendations.\"\"\"\n    # Get model columns\n    model_columns = ['Regex', 'SpaCy', 'Zero-Shot', 'Transformer', 'Custom NER', 'Hybrid']\n    available_models = [col for col in model_columns if col in df.columns]\n    \n    if len(available_models) == 0:\n        return df\n    \n    # Calculate agreement between models (where non-null)\n    def get_agreement(row):\n        values = [row[col] for col in available_models if pd.notna(row[col])]\n        if len(values) <= 1:\n            return None\n        \n        # Calculate standard deviation as measure of agreement\n        return np.std(values)\n    \n    df['Model_Agreement'] = df.apply(get_agreement, axis=1)\n    \n    # Calculate success rate (non-null extractions)\n    model_success = {}\n    for model in available_models:\n        model_success[model] = df[model].notna().mean() * 100\n    \n    # Simple voting mechanism for recommended value\n    def get_recommended_value(row):\n        values = [row[col] for col in available_models if pd.notna(row[col])]\n        if not values:\n            return None\n        \n        # If there's only one valid value, use it\n        if len(values) == 1:\n            return values[0]\n        \n        # If hybrid model has a value, prioritize it\n        if 'Hybrid' in available_models and pd.notna(row['Hybrid']):\n            return row['Hybrid']\n        \n        # Otherwise, get the most common value\n        # In case of tie, prefer the more common years of experience\n        from collections import Counter\n        counts = Counter(values)\n        most_common = counts.most_common()\n        \n        if len(most_common) > 1 and most_common[0][1] == most_common[1][1]:\n            # If tie, take the average\n            return sum(values) / len(values)\n        else:\n            return most_common[0][0]\n    \n    df['Recommended_Value'] = df.apply(get_recommended_value, axis=1)\n    \n    # Add model performance summary\n    model_performance = pd.DataFrame({\n        'Success_Rate': model_success\n    }).sort_values('Success_Rate', ascending=False)\n    \n    # Determine best model based on success rate\n    best_model = model_performance.index[0] if not model_performance.empty else None\n    \n    # Print performance summary\n    print(\"\\nModel Performance Summary:\")\n    print(model_performance)\n    print(f\"\\nRecommended Model: {best_model}\")\n    \n    return df\n\n# Main function\ndef main():\n    \"\"\"Main function to run the experience extractor.\"\"\"\n    print(\"Experience Extractor for Job Descriptions\")\n    print(\"=======================================\")\n    \n    # File path\n    file_path = input(\"Enter the path to the Excel file containing job descriptions: \")\n    \n    # Read data\n    df = read_jd_data(file_path)\n    if df.empty:\n        print(\"No data to process. Exiting.\")\n        return\n    \n    # Check column names\n    print(\"\\nAvailable columns:\")\n    for col in df.columns:\n        print(f\"- {col}\")\n    \n    jd_column = input(\"\\nEnter the name of the column containing job descriptions [default: JD_Text]: \")\n    if not jd_column:\n        jd_column = \"JD_Text\"\n    \n    if jd_column not in df.columns:\n        print(f\"Column '{jd_column}' not found. Exiting.\")\n        return\n    \n    # Process JDs\n    start_time = time.time()\n    result_df = process_all_jds(df, jd_column)\n    end_time = time.time()\n    \n    print(f\"\\nProcessing completed in {end_time - start_time:.2f} seconds\")\n    \n    # Save results\n    output_path = input(\"Enter the path to save the results Excel file [default: experience_extraction_results.xlsx]: \")\n    if not output_path:\n        output_path = \"experience_extraction_results.xlsx\"\n    \n    result_df.to_excel(output_path)\n    print(f\"Results saved to {output_path}\")\n    \n    # Print some sample results\n    print(\"\\nSample Results (first 5 rows):\")\n    print(result_df.head())\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T21:57:28.817088Z","iopub.execute_input":"2025-05-06T21:57:28.817750Z","iopub.status.idle":"2025-05-06T22:30:35.678747Z","shell.execute_reply.started":"2025-05-06T21:57:28.817717Z","shell.execute_reply":"2025-05-06T22:30:35.678073Z"}},"outputs":[{"name":"stdout","text":"Experience Extractor for Job Descriptions\n=======================================\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the path to the Excel file containing job descriptions:  /kaggle/input/data-new-assignment/Job Descriptions 2.xlsx\n"},{"name":"stdout","text":"Successfully loaded 2997 job descriptions\n\nAvailable columns:\n- JD_Text\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter the name of the column containing job descriptions [default: JD_Text]:  \n"},{"name":"stdout","text":"Initializing models...\n","output_type":"stream"},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Processing job descriptions...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2997/2997 [32:50<00:00,  1.52it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nModel Performance Summary:\n             Success_Rate\nZero-Shot       81.481481\nHybrid          78.478478\nCustom NER      71.871872\nRegex           69.002336\nTransformer     43.843844\nSpaCy           41.207875\n\nRecommended Model: Zero-Shot\n\nProcessing completed in 1972.57 seconds\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the path to save the results Excel file [default: experience_extraction_results.xlsx]:  \n"},{"name":"stdout","text":"Results saved to experience_extraction_results.xlsx\n\nSample Results (first 5 rows):\n                                             JD_Text  Regex  SpaCy  Zero-Shot  \\\n0  \\n**Overview  \\n  \\n** Lazydays RV is looking ...    3.0    3.0       12.0   \n1  \\n**Ãrea De AtuaÃ§Ã£o  \\n  \\n** TÃ©cnico em I...    NaN    NaN        NaN   \n2  \\n\\n\\nðŸ”µ Capitole is still growing and we wa...    NaN    NaN        8.5   \n3  \\n\\n\\nAs a Solutions Engineer, you will work c...   12.0    NaN        8.5   \n4  \\n\\n\\n**ABOUT DAYONE**\\n\\nDayOne is a global l...    5.0    5.0        4.0   \n\n   Transformer  Custom NER  Hybrid  Model_Agreement  Recommended_Value  \n0          3.0         3.0     3.0         3.354102                3.0  \n1          NaN         NaN     NaN              NaN                NaN  \n2          NaN         NaN     NaN              NaN                8.5  \n3          NaN         7.0    12.0         2.190177               12.0  \n4          5.0         5.0     5.0         0.372678                5.0  \n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}